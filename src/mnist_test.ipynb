{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow基本使用\n",
    "\n",
    "## [一个最基本的例子](http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_pros.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "y_ = tf.placeholder(\"float\", [None,10])\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**上述为定义的过程**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(64)\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print('accuracy:{}'.format(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 偏好值初始化\n",
    "def bias_variable(shape):\n",
    "    initial=tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 卷积过程\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(input=x,filter=W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "# 池化过程\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],\n",
    "                         strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "def relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def softmax(x):\n",
    "    return tf.nn.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_x = tf.placeholder(tf.float32,[None,784],name='cnn_x')\n",
    "cnn_y = tf.placeholder(tf.float32, [None,10],name='cnn_y')\n",
    "\n",
    "image = tf.reshape(cnn_x,shape=[-1,28,28,1])\n",
    "\n",
    "w_1 = weight_variable([5,5,1,32])\n",
    "conv1 = conv2d(image,w_1)\n",
    "pool = max_pool_2x2(conv1)\n",
    "relu1 = relu(pool)\n",
    "\n",
    "w_2 = weight_variable([5,5,32,64])\n",
    "\n",
    "conv2 = conv2d(relu1,w_2)\n",
    "\n",
    "w_fc1 = weight_variable([14*14*64,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "conv2_flat = tf.reshape(conv2, [-1, 14 * 14 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(conv2_flat, w_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "#全连接层fc2\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "# 直接经过softmax进行分类\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(cnn_y * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))  # loss\n",
    "train_step = tf.train.GradientDescentOptimizer(1e-4).minimize(cross_entropy)\n",
    "init = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(10000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(64)\n",
    "        test=sess.run(image,feed_dict={cnn_x:batch_xs,cnn_y:batch_ys})\n",
    "        correct_prediction = tf.equal(tf.argmax(cnn_y,1), tf.argmax(prediction,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "            print('accuracy:{}'.format(sess.run(accuracy,feed_dict={cnn_x:mnist.test.images, cnn_y:mnist.test.labels})))\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(64)\n",
    "        sess.run(train_step2, feed_dict={cnn_x: batch_xs, cnn_y: batch_ys})\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(cnn_y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print('accuracy:{}'.format(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_x = tf.placeholder(tf.float32,[None,784],name='cnn_x')/255\n",
    "cnn_y = tf.placeholder(tf.float32, [None,10],name='cnn_y')\n",
    "x_image = tf.reshape(cnn_x, [-1, 28, 28, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([5,5, 1,32]) # patch 5x5, in size 1, out size 32\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 28x28x32\n",
    "h_pool1 = max_pool_2x2(h_conv1)                                         # output size 14x14x32\n",
    "\n",
    "# ## conv2 layer ##\n",
    "W_conv2 = weight_variable([5,5, 32, 64]) # patch 5x5, in size 32, out size 64\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 14x14x64\n",
    "h_pool2 = max_pool_2x2(h_conv2)                                         # output size 7x7x64\n",
    "\n",
    "# ## fc1 layer ##\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "# [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# ## fc2 layer ##\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+ b_fc2)\n",
    "# prediction = tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(64)\n",
    "        print(batch_xs.shape)\n",
    "        test=sess.run(image,feed_dict={cnn_x:batch_xs,cnn_y:batch_ys,keep_prob:0.5})\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(cnn_y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "            print('accuracy:{}'.format(sess.run(accuracy,feed_dict={cnn_x:mnist.test.images, cnn_y:mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一个卷积池为3x3的卷积池，输出为7个\n",
    "W_1 = weight_variable([3,3,1,3])\n",
    "#经过卷积过程\n",
    "conv1 = conv2d(image,W_1)\n",
    "#池化过程\n",
    "pool1 = max_pool_2x2(conv1)\n",
    "#relu过程\n",
    "relu1 = relu(pool1)\n",
    "\n",
    "#第二个卷积池，3x3，输出为一个图\n",
    "W_2 = weight_variable([3,3,3,1])\n",
    "conv2 = conv2d(relu1,W_2)\n",
    "\n",
    "#全连接层fc1\n",
    "w_fc1 = weight_variable([14*14,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "conv2_flat = tf.reshape(conv2, [-1, 14 * 14 * 1])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(conv2_flat, w_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, 1)\n",
    "\n",
    "#全连接层fc2\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "# 直接经过softmax进行分类\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(cnn_y * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))  # loss\n",
    "train_step2 = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
